# BME_bachelor_thesis (2024.07~2024.12)

&nbsp;

## 🧠 Hospital system with self-driving Ambulance using Unity

&nbsp;

## 🔗 출처 및 라이선스
### 1. Autonomous Driving with Unity and BMW: 240 Million Virtual Kilometers -NICK DAVIS
 - https://unity.com/kr/blog/industry/bmw-automotive-lifecycle
### 2. Self-Driving Ambulance for Emergency Application -Mainak Kumar Das
- https://ieeexplore.ieee.org/document/9614822

     
&nbsp;

## 📑 목차

1. [📌 프로젝트 개요](#1--프로젝트-개요)  
2. [🔧 구성 요소](#2--구성-요소)  
3. [💻 사용 기술](#3--사용-기술)  
4. [🧭 동작 흐름 요약](#4--동작-흐름-요약)  
5. [💻 코드 실행 방법](#5--코드-실행-방법)  
6. [📷 시연 영상/이미지](#6--시연-영상--이미지)  
7. [🌟 기대 효과/ 한계점 및 개선점](#7--기대-효과)  

   
&nbsp;
## 1. 📌 프로젝트 개요

효율적인 응급 대응은 특히 전문 진료가 필요한 환자의 경우 생명을 구하는 데 결정적인 역할을 합니다.  
그러나 기존의 앰뷸런스 시스템은 다음과 같은 문제를 겪고 있습니다:

- **전문 병원의 제한된 가용성**
- **가장 가까운 앰뷸런스를 신속히 배차하는 어려움**
- **복잡한 도심 환경에서의 이동 지연**

이러한 문제를 해결하기 위해, 본 프로젝트는  
**실시간 환자 우선순위 판단과 자동 배차 기능을 결합한 자율주행 앰뷸런스 시스템**을 개발하여  
응급 이송 시간을 최적화하는 것을 목표로 합니다.
  
&nbsp;

## 2. 🎯 기획 의도

기존의 수동적인 앰뷸런스 운영 방식은 교통 체증, 병원 혼잡도, 인력 부족 등 다양한 변수로 인해  
환자 이송 지연이라는 치명적인 문제를 발생시킵니다.  

본 시스템은 다음과 같은 점에 중점을 둡니다:

- **카메라 및 OpenCV 기반 차선 인식**으로 멀티 차선 도로를 자율적으로 주행  
- **Unity의 Raycast** 기능을 이용하여 주변 차량을 감지하고, 차선 변경 및 속도 조절 자동 수행  
- 환자 상태에 따른 **실시간 우선순위 판단과 자동 경로 설정** 기능을 결합  
- **병원의 거리, 혼잡도, 전문 진료 가능 여부**를 고려하여 가장 적합한 병원으로 자동 이송

이를 통해 응급 환자의 생존 가능성을 높이고, 전체 응급 시스템의 효율을 향상시킬 수 있습니다.
  
&nbsp;

## 3. 🏭 기존 기술의 활용과 확장 가능성

본 프로젝트는 다양한 기술 요소를 유기적으로 결합하여 다음과 같은 장점을 가집니다:

- Unity 시뮬레이터를 활용한 현실적인 도로 환경 구현  
- 카메라와 OpenCV 기반의 차선 탐지 알고리즘으로 자율주행 구현  
- Raycast 기반 충돌 회피 로직으로 안전한 차량 간 거리 유지 및 회피 가능  
- 병원 데이터와 연동된 실시간 판단 시스템으로 경로 최적화 및 병원 자동 연결  

이 시스템은 향후 다음과 같은 영역으로 확장 가능합니다:

- 실제 자율주행 구급차량 시스템에의 적용
- 재난 대응용 드론 또는 로봇 응급 구조 시스템과 연계
- 스마트 시티 인프라와 연동한 병원-도로 네트워크 구축
- 고령자·장애인을 위한 비대면 응급 호출 플랫폼으로 발전

&nbsp;
## 2. 🔧 구성 요소

| 구성 요소                           | 설명                                                                                         | 
|------------------------------------|----------------------------------------------------------------------------------------------|
| **Unity**                          | 자율주행 시스템 전체 시뮬레이션을 구성하는 데 사용된 엔진. 물리 기반 시뮬레이션 및 Raycast 활용. |
| **SimplePoly City – Low Poly Assets** | 경량 도시 환경을 구성하기 위한 로우 폴리 모델 패키지. CPU/GPU 성능을 최적화하며 다양한 도로, 건물, 환경 요소 포함. |

<img width="1299" height="719" alt="image" src="https://github.com/user-attachments/assets/f8dc8a55-2078-4ec2-a6f0-f4e6bb257af4" />


&nbsp;

## 3. 💻 사용 기술

| 기술 | 내용 |
|------|------|
| 💻 OS 및 환경 | Ubuntu 22.04, ROS2 Humble |
| 💬 사용 언어 | Python, DSR |
| 🔗 통신 미들웨어 | ROS2 (Publisher / Subscriber 기반 노드 통신) |
| 🧪 순응제어 | Doosan M0609 Force 센서를 활용한 충돌 감지 및 위치 파악 |
| 🧠 서브 제어 컨트롤러 | Raspberry Pi (로컬 ROS2 노드 실행 및 장치 제어) |
| 🎮 인터페이스 | 사용자 입력 기반 물품 선택 |
| 🖥 디스플레이/음성 | Raspberry Pi + LCD + 음성 출력 |

&nbsp;
## 4. 🧭 동작 흐름 요약

## 🏥 1. 병원 시스템 (Hospital System)

<img width="600" alt="병원 시스템 이미지1" src="https://github.com/user-attachments/assets/0166dceb-dda2-4f6e-95df-c504b9aa02f0" />
<img width="300" alt="병원 시스템 이미지2" src="https://github.com/user-attachments/assets/a5ddc868-2ccf-4d4d-a410-53f0ded87d1e" />

병원 시스템은 크게 **환자(People)**, **병원(Hospitals)**, **앰뷸런스(Ambulances)**의 세 가지 요소로 구성됩니다.

### 📌 시스템 구성 흐름

1. **환자 요청 발생**
   - 환자의 요청은 **포아송 분포(Poisson Distribution)**를 기반으로 무작위로 생성되며,  
     각 요청은 **증상(Symptom)**과 **위급도(Severity: 1~5)** 정보를 포함합니다.
   - 증상 종류: 신경외과, 심장과, 내과, 외과, 흉부외과, 소아과, 정신과, 산부인과 등

2. **병원 선택 기준**
   - 해당 증상과 위급도에 맞는 의료 인력이 단 한 곳의 병원에만 존재할 경우, 해당 병원으로 바로 배정됩니다.
   - 여러 병원이 가능한 경우, 아래 기준으로 **우선순위 점수(Priority Score)**를 계산합니다:
     - **거리 순위(Proximity Rank)**: 가장 가까운 병원 = 1, 두 번째 = 2 ...
     - **혼잡도 점수(Congestion Score)**: 낮음 = 1, 높음 = 2
     - → 두 값을 합산하여 총점이 가장 낮은 병원을 선택  
     - 점수가 동일한 경우에는 무작위로 하나를 선택

3. **앰뷸런스 배정 및 출동**
   - 가장 가까운 대기 중인 앰뷸런스를 환자에게 배정  
   - 가장 가까운 앰뷸런스가 사용 중일 경우, 그다음 가까운 대기 앰뷸런스를 배정  
   - 배정된 앰뷸런스는 환자 위치로 이동 → 환자 픽업 → 지정 병원으로 이송

4. **대기 리스트 관리**
   - 사용 가능한 앰뷸런스가 없을 경우, 요청은 **대기 리스트(Waitlist)**에 추가  
   - 앰뷸런스가 이송을 마치고 복귀하면, 대기 리스트에서 **순차적으로** 다음 요청을 처리

---

## 🚑 2. 앰뷸런스 - 차선 인식 시스템 (Lane Detection)

<img width="800" alt="차선 인식 이미지" src="https://github.com/user-attachments/assets/f48e8c97-4ac4-41ff-b5e2-11432cd82aee" />

- 차량에 장착된 **카메라가 1초마다 도로 이미지를 캡처**
- OpenCV를 통해 다음 과정을 거쳐 차선을 검출:
  1. 관심 영역(ROI) 설정
  2. 그레이스케일 변환
  3. Canny 엣지 검출
  4. 허프 변환(Hough Transform)으로 선 인식

### 🛣️ 도로 구조
- **4차선 구조 (2개 차선 × 양방향)**
- 선은 세 가지로 분류:
  - 중앙선 (Central Line)
  - 점선 (Dashed Line)
  - 가장자리 선 / 진입 금지 (Edge / Not Walkable)

### 🚘 차선 정의
- **Lane 1**: 점선과 가장자리 선 사이  
  → 카메라 뷰: `중앙선 → 점선 → 가장자리 선` → 현재 차량은 Lane 1
- **Lane 2**: 중앙선과 점선 사이  
  → 카메라 뷰: `점선1 → 중앙선 → 점선2` → 현재 차량은 Lane 2

> 일반 차량은 Lane 1 또는 Lane 2에서만 주행 가능하며,  
> **앰뷸런스는 필요 시 중앙선을 넘어갈 수 있음** (단, 주변 차량이 없을 때만 허용)

<img width="600" alt="차선 예시 이미지" src="https://github.com/user-attachments/assets/d0f8b8cb-1e9c-45c3-a1b2-ff88ea31dd2a" />

---

## 🚨 3. 앰뷸런스 - 충돌 회피 시스템 (Avoid Collision)

<img width="700" alt="충돌 회피 이미지" src="https://github.com/user-attachments/assets/4e8172a8-2391-4780-b1a5-45abf2317cdf" />

- **Unity의 Raycast**를 사용하여 차량 전방 **20m 이내**에 다른 차량이 있는지 탐지  
- 감지 시 **자동으로 회피 동작 수행**

### ⚙️ 속도 제어
- 기본 속도: `5f`  
- 감속 시: `3f`  
- 가속 시: 최대 `7f`

### 🚧 회피 시나리오

1. **일반 차량 또는 앰뷸런스 간 회피**
   - 인접 차선이 비어 있으면 → 해당 차선으로 **차선 변경**
   - 인접 차선이 막혀 있으면 → **속도 감속**

2. **앰뷸런스 vs 일반 차량**
   - 인접 차선이 비어 있으면 → 앰뷸런스가 **차선 변경 후 가속**
   - 인접 차선이 막혀 있지만, 앞 차량이 이동 가능하면 → **앞 차량이 가속하여 공간 확보**
     - 앰뷸런스는 그대로 주행하며 속도를 높임
   - 앞 차량도 이동 불가능한 경우 → **기존 차선 및 속도 유지**


## ✅ 결과

<img width="857" height="341" alt="image" src="https://github.com/user-attachments/assets/3a3af50d-4ca5-4de7-8538-c315d31d9a54" />

- 사용자의 눈 움직임만으로 로봇팔이 정확한 방향 전환 및 집기 동작 성공  
- LSTM 기반 EOG 분류 모델과 로봇팔 동작 시스템의 실시간 연동 가능성 확인

&nbsp;


## 5. 💻 코드 실행 방법

### 🤖 EogDeepLearning-Robot
- 코드: [`eog_deeplearning`](./Arduino/Arduino/eog_deeplearning/eog_deeplearning-DESKTOP-O965BML.ino)


&nbsp;



## 6. 📷 시연 영상 / 이미지
### 경희대학교 전자공학과 졸업논문 발표
<img width="670" height="481" alt="image" src="https://github.com/user-attachments/assets/ee818f96-756f-4eaf-9bdc-710e653cd323" />

&nbsp;

### 경희대학교 캡스톤 디자인 대회 최우수상
![캡스톤디자인대회전체사진](https://github.com/user-attachments/assets/d9fc142f-a1ec-436a-888b-d0d8fbc1dbe4)

![캡스톤디자인대회최우수상](https://github.com/user-attachments/assets/9c34a8d0-3c7f-4ca7-8bd4-0bce211a80c4)

&nbsp;

> https://youtu.be/0Lg0ZxRh0jA

&nbsp;
## 7. 🌟 기대 효과
EOG 센서는 빠른 반응 속도를 제공해 사용자의 의도를 **즉시 반영**할 수 있습니다.  
이를 통해 로봇팔의 **실시간 제어**가 가능해져 시스템의 효율성이 높아집니다.

또한 피부에 부착하는 방식이므로, 수술이나 복잡한 설치 과정 없이 **몸이 불편한 사용자도 간편하게 사용 가능**하여 **접근성과 안전성**이 매우 뛰어납니다.  

> 이를 활용해 산업, 의료, 서비스 등 다양한 분야로 **응용 범위를 확장**할 수 있습니다.

&nbsp;

### 🛠️ 활용 방안

- **보조기기**: 신체 일부가 불편한 사람들을 위한 **일상 동작 지원 장치**로 사용 가능  
- **재활치료**: 사용자의 자율성 증진을 통해 **회복을 돕는 치료 보조 장치**로 활용  
- **산업 분야**: 정밀 제어가 필요한 제조 환경 등에서 자동화 도구로 활용  
- **서비스 분야**: 음식 및 음료 서빙 등 **비접촉 자동화 서비스 시스템**에 적용 가능  
  (예: 카페, 레스토랑 등)

&nbsp;
 
### 🔍 결론 및 제언

EOG 센서를 이용한 로봇팔 제어 기술은 **생체 신호 기반의 정밀하고 신속한 제어**를 가능하게 합니다.  
비침습적 인터페이스를 통해 **사용자의 편의성과 안전성을 보장**하며, 다양한 환경과 작업 조건에서 **효율적으로 적용**될 수 있습니다.

> 여러 분야에서의 활용 가능성을 고려할 때, 이 기술은 인간의 생활을 더욱 **풍요롭게** 하고,  
> 새로운 **혁신을 이끌어 낼 수 있는 잠재력**을 가지고 있습니다.


### 📌 **향후 제언**
- 지속적인 연구 및 개발  
- 사용자 중심의 기술 설계  
- **윤리적 고려**와 **사회적 수용성** 확보

> 이를 통해 EOG 기반 로봇 제어 기술이 더욱 발전하여  
> 우리의 삶에 **긍정적인 영향**을 미치기를 기대합니다.

&nbsp;
## 🙌 팀원

-윤하연, 정서윤, 안병호 


